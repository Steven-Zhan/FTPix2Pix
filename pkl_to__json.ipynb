{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c3af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing block_hammer_beat_D435_pkl...\n",
      "Processing block_handover_D435_pkl...\n",
      "Processing blocks_stack_easy_D435_pkl...\n",
      "Data processed and saved to extracted_resized_head_camera_data.pkl\n",
      "load over\n",
      "block_hammer_beat_D435_pkl\n",
      "episode0\n",
      "episode1\n",
      "episode2\n",
      "episode3\n",
      "episode4\n",
      "episode5\n",
      "episode6\n",
      "episode7\n",
      "episode8\n",
      "episode9\n",
      "episode10\n",
      "episode11\n",
      "episode12\n",
      "episode13\n",
      "episode14\n",
      "episode15\n",
      "episode16\n",
      "episode17\n",
      "episode18\n",
      "episode19\n",
      "episode20\n",
      "episode21\n",
      "episode22\n",
      "episode23\n",
      "episode24\n",
      "episode25\n",
      "episode26\n",
      "episode27\n",
      "episode28\n",
      "episode29\n",
      "episode30\n",
      "episode31\n",
      "episode32\n",
      "episode33\n",
      "episode34\n",
      "episode35\n",
      "episode36\n",
      "episode37\n",
      "episode38\n",
      "episode39\n",
      "episode40\n",
      "episode41\n",
      "episode42\n",
      "episode43\n",
      "episode44\n",
      "episode45\n",
      "episode46\n",
      "episode47\n",
      "episode48\n",
      "episode49\n",
      "episode50\n",
      "episode51\n",
      "episode52\n",
      "episode53\n",
      "episode54\n",
      "episode55\n",
      "episode56\n",
      "episode57\n",
      "episode58\n",
      "episode59\n",
      "episode60\n",
      "episode61\n",
      "episode62\n",
      "episode63\n",
      "episode64\n",
      "episode65\n",
      "episode66\n",
      "episode67\n",
      "episode68\n",
      "episode69\n",
      "episode70\n",
      "episode71\n",
      "episode72\n",
      "episode73\n",
      "episode74\n",
      "episode75\n",
      "episode76\n",
      "episode77\n",
      "episode78\n",
      "episode79\n",
      "episode80\n",
      "episode81\n",
      "episode82\n",
      "episode83\n",
      "episode84\n",
      "episode85\n",
      "episode86\n",
      "episode87\n",
      "episode88\n",
      "episode89\n",
      "episode90\n",
      "episode91\n",
      "episode92\n",
      "episode93\n",
      "episode94\n",
      "episode95\n",
      "episode96\n",
      "episode97\n",
      "episode98\n",
      "episode99\n",
      "block_handover_D435_pkl\n",
      "episode0\n",
      "episode1\n",
      "episode2\n",
      "episode3\n",
      "episode4\n",
      "episode5\n",
      "episode6\n",
      "episode7\n",
      "episode8\n",
      "episode9\n",
      "episode10\n",
      "episode11\n",
      "episode12\n",
      "episode13\n",
      "episode14\n",
      "episode15\n",
      "episode16\n",
      "episode17\n",
      "episode18\n",
      "episode19\n",
      "episode20\n",
      "episode21\n",
      "episode22\n",
      "episode23\n",
      "episode24\n",
      "episode25\n",
      "episode26\n",
      "episode27\n",
      "episode28\n",
      "episode29\n",
      "episode30\n",
      "episode31\n",
      "episode32\n",
      "episode33\n",
      "episode34\n",
      "episode35\n",
      "episode36\n",
      "episode37\n",
      "episode38\n",
      "episode39\n",
      "episode40\n",
      "episode41\n",
      "episode42\n",
      "episode43\n",
      "episode44\n",
      "episode45\n",
      "episode46\n",
      "episode47\n",
      "episode48\n",
      "episode49\n",
      "episode50\n",
      "episode51\n",
      "episode52\n",
      "episode53\n",
      "episode54\n",
      "episode55\n",
      "episode56\n",
      "episode57\n",
      "episode58\n",
      "episode59\n",
      "episode60\n",
      "episode61\n",
      "episode62\n",
      "episode63\n",
      "episode64\n",
      "episode65\n",
      "episode66\n",
      "episode67\n",
      "episode68\n",
      "episode69\n",
      "episode70\n",
      "episode71\n",
      "episode72\n",
      "episode73\n",
      "episode74\n",
      "episode75\n",
      "episode76\n",
      "episode77\n",
      "episode78\n",
      "episode79\n",
      "episode80\n",
      "episode81\n",
      "episode82\n",
      "episode83\n",
      "episode84\n",
      "episode85\n",
      "episode86\n",
      "episode87\n",
      "episode88\n",
      "episode89\n",
      "episode90\n",
      "episode91\n",
      "episode92\n",
      "episode93\n",
      "episode94\n",
      "episode95\n",
      "episode96\n",
      "episode97\n",
      "episode98\n",
      "episode99\n",
      "blocks_stack_easy_D435_pkl\n",
      "episode0\n",
      "episode1\n",
      "episode2\n",
      "episode3\n",
      "episode4\n",
      "episode5\n",
      "episode6\n",
      "episode7\n",
      "episode8\n",
      "episode9\n",
      "episode10\n",
      "episode11\n",
      "episode12\n",
      "episode13\n",
      "episode14\n",
      "episode15\n",
      "episode16\n",
      "episode17\n",
      "episode18\n",
      "episode19\n",
      "episode20\n",
      "episode21\n",
      "episode22\n",
      "episode23\n",
      "episode24\n",
      "episode25\n",
      "episode26\n",
      "episode27\n",
      "episode28\n",
      "episode29\n",
      "episode30\n",
      "episode31\n",
      "episode32\n",
      "episode33\n",
      "episode34\n",
      "episode35\n",
      "episode36\n",
      "episode37\n",
      "episode38\n",
      "episode39\n",
      "episode40\n",
      "episode41\n",
      "episode42\n",
      "episode43\n",
      "episode44\n",
      "episode45\n",
      "episode46\n",
      "episode47\n",
      "episode48\n",
      "episode49\n",
      "episode50\n",
      "episode51\n",
      "episode52\n",
      "episode53\n",
      "episode54\n",
      "episode55\n",
      "episode56\n",
      "episode57\n",
      "episode58\n",
      "episode59\n",
      "episode60\n",
      "episode61\n",
      "episode62\n",
      "episode63\n",
      "episode64\n",
      "episode65\n",
      "episode66\n",
      "episode67\n",
      "episode68\n",
      "episode69\n",
      "episode70\n",
      "episode71\n",
      "episode72\n",
      "episode73\n",
      "episode74\n",
      "episode75\n",
      "episode76\n",
      "episode77\n",
      "episode78\n",
      "episode79\n",
      "episode80\n",
      "episode81\n",
      "episode82\n",
      "episode83\n",
      "episode84\n",
      "episode85\n",
      "episode86\n",
      "episode87\n",
      "episode88\n",
      "episode89\n",
      "episode90\n",
      "episode91\n",
      "episode92\n",
      "episode93\n",
      "episode94\n",
      "episode95\n",
      "episode96\n",
      "episode97\n",
      "episode98\n",
      "episode99\n",
      "Data converted to JSON and saved to output.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "\n",
    "class HeadCameraDataProcessor:\n",
    "    '''\n",
    "    Pre-processing .pkl data:\n",
    "    1. Extract head_camera data from .pkl files.\n",
    "    2. Sample 20 .pkl files from each episode using Gaussian.\n",
    "    3. Resize the RGB images to 128x128 and normalize them.\n",
    "    4. Save the processed data into `extracted_resized_head_camera_data.pkl`.\n",
    "    5. Convert the processed data to JSON format and write to file with specific format.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, subdataset_dirs, num_samples=20, output_file='extracted_resized_head_camera_data.pkl',\n",
    "                 json_output_file='output.json'):\n",
    "        self.subdataset_dirs = subdataset_dirs\n",
    "        self.num_samples = num_samples\n",
    "        self.output_file = output_file\n",
    "        self.json_output_file = json_output_file\n",
    "\n",
    "    def extract_head_camera_data(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            return data['observation']['head_camera']\n",
    "\n",
    "    def sample_pkl_files(self, episode_dir):\n",
    "        pkl_files = [f for f in os.listdir(episode_dir) if f.endswith('.pkl')]\n",
    "        pkl_files.sort()\n",
    "        # 只考虑第一个到倒数第二个文件\n",
    "        available_files = pkl_files[:-1]\n",
    "        total_available_files = len(available_files)\n",
    "        # if total_available_files < self.num_samples:\n",
    "        #     raise ValueError(f\"可用文件数量 {total_available_files} 少于要采样的数量 {self.num_samples}\")\n",
    "        idx = np.arange(total_available_files)\n",
    "        weights = np.exp(-0.5 * ((idx - total_available_files // 2) / (total_available_files // 4)) ** 2)\n",
    "        weights /= weights.sum()\n",
    "        sampled_files = np.random.choice(available_files, size=self.num_samples, p=weights, replace=False)\n",
    "        before = []\n",
    "        after = []\n",
    "        for file in sampled_files:\n",
    "            file_path = os.path.join(episode_dir, file)\n",
    "            before.append(self.extract_head_camera_data(file_path))\n",
    "            current_index = pkl_files.index(file)\n",
    "            next_file = pkl_files[current_index + 1]\n",
    "            next_file_path = os.path.join(episode_dir, next_file)\n",
    "            after.append(self.extract_head_camera_data(next_file_path))\n",
    "        return before, after\n",
    "\n",
    "    def resize_and_normalize_image(self, image_array):\n",
    "        image = Image.fromarray(image_array)\n",
    "        image = image.resize((128, 128))\n",
    "        image_array = np.array(image)\n",
    "        return np.round(image_array / 255.0, 4)\n",
    "\n",
    "    def process_subdataset(self, subdataset_dir):\n",
    "        all_data = {}\n",
    "        for episode_num in range(100):\n",
    "            episode_dir = os.path.join(subdataset_dir, f\"episode{episode_num}\")\n",
    "            if os.path.exists(episode_dir):\n",
    "                before_data, after_data = self.sample_pkl_files(episode_dir)\n",
    "                resized_data = []\n",
    "                for i in range(len(before_data)):\n",
    "                    resized_before = {\n",
    "                        'intrinsic_cv': before_data[i]['intrinsic_cv'],\n",
    "                        'extrinsic_cv': before_data[i]['extrinsic_cv'],\n",
    "                        'cam2world_gl': before_data[i]['cam2world_gl'],\n",
    "                        'rgb': self.resize_and_normalize_image(before_data[i]['rgb'])\n",
    "                    }\n",
    "                    resized_after = {\n",
    "                        'intrinsic_cv': after_data[i]['intrinsic_cv'],\n",
    "                        'extrinsic_cv': after_data[i]['extrinsic_cv'],\n",
    "                        'cam2world_gl': after_data[i]['cam2world_gl'],\n",
    "                        'rgb': self.resize_and_normalize_image(after_data[i]['rgb'])\n",
    "                    }\n",
    "                    resized_data.append((resized_before, resized_after))\n",
    "                all_data[f\"episode{episode_num}\"] = resized_data\n",
    "        return all_data\n",
    "\n",
    "    def process_all_subdatasets(self):\n",
    "        all_subdataset_data = {}\n",
    "        for subdataset_dir in self.subdataset_dirs:\n",
    "            subdataset_name = os.path.basename(subdataset_dir)\n",
    "            print(f\"Processing {subdataset_name}...\")\n",
    "            subdataset_data = self.process_subdataset(subdataset_dir)\n",
    "            all_subdataset_data[subdataset_name] = subdataset_data\n",
    "        with open(self.output_file, 'wb') as output_file:\n",
    "            pickle.dump(all_subdataset_data, output_file)\n",
    "        print(f\"Data processed and saved to {self.output_file}\")\n",
    "\n",
    "    def convert_to_json(self):\n",
    "        file_path = self.output_file\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        print(\"load over\")\n",
    "        with open(self.json_output_file, 'w') as json_file:\n",
    "            for subdataset in data:\n",
    "                print(subdataset)\n",
    "                for episode in data[subdataset]:\n",
    "                    print(episode)\n",
    "                    episode_data = data[subdataset][episode]\n",
    "                    for before_data, after_data in episode_data:\n",
    "                        original_images = before_data['rgb'].tolist()\n",
    "                        edited_images = after_data['rgb'].tolist()\n",
    "                        prompts = 'The robot is '+ str(subdataset)[0:-9]+ \", please predict what the head camera will see 50 frames later.\"\n",
    "                        json_file.write(json.dumps({\"before\": original_images}) + '\\n')\n",
    "                        json_file.write(json.dumps({\"after\": edited_images}) + '\\n')\n",
    "                        json_file.write(json.dumps({\"prompt\": prompts}) + '\\n')\n",
    "        print(\"Data converted to JSON and saved to\", self.json_output_file)\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    subdataset_dirs = [\n",
    "        'datasets/block_hammer_beat_D435_pkl',\n",
    "        'datasets/block_handover_D435_pkl',\n",
    "        'datasets/blocks_stack_easy_D435_pkl'\n",
    "    ]\n",
    "\n",
    "    processor = HeadCameraDataProcessor(subdataset_dirs=subdataset_dirs, num_samples=20)\n",
    "    processor.process_all_subdatasets()\n",
    "    processor.convert_to_json()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
